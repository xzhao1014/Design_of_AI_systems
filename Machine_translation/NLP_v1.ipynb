{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "LDTk9JT3nKHo"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import numpy as np\n",
    "\n",
    "def word_split(text):\n",
    "    punc = string.punctuation\n",
    "    for i in punc:\n",
    "        text = text.replace(i,' ')\n",
    "    words = text.split()\n",
    "    return words\n",
    "\n",
    "def word_counts(text):\n",
    "    from collections import Counter\n",
    "    # Count numbers of each words\n",
    "    counts = Counter()\n",
    "    words = word_split(text)\n",
    "    counts.update(words)\n",
    "    df = pd.DataFrame([counts]).T\n",
    "    df.rename(columns = {0:'Counts'},inplace=True)\n",
    "    # Sorting\n",
    "    df = df.sort_values(by='Counts',ascending=False)\n",
    "    return df\n",
    "\n",
    "def lang_model(text,word_list):\n",
    "    df = word_counts(text)\n",
    "    words = word_split(text)\n",
    "    p = df.at[word_list[0],'Counts']/len(words)\n",
    "    for i in range(len(word_list)-1): # to each word as input\n",
    "        cnt=1 # Set the initial value to 1 in case of 0 presense of the word combination\n",
    "        for j in range(len(words)-1): # search the count in the training data \n",
    "            if words[j] == word_list[i]:\n",
    "                if words[j+1] == word_list[i+1]:\n",
    "                    cnt += 1\n",
    "                else:\n",
    "                    continue\n",
    "            else:\n",
    "                continue\n",
    "        p = p*cnt/(1+df.at[word_list[i],'Counts'])\n",
    "    return p\n",
    "\n",
    "def trans_model(text_en,text_sv,lines_en,lines_sv,df_trans):\n",
    "    df_en = word_counts(text_en)\n",
    "    df_sv = word_counts(text_sv)\n",
    "    df_counts = pd.DataFrame(index=df_en.index,columns=df_sv.index)\n",
    "    df_counts.loc[:] = 0     # Set all counts to zero\n",
    "    df_counts_en = pd.DataFrame(index=df_en.index,columns=['c(e)'])\n",
    "    df_counts_en.iloc[:]=0     # Set all counts to zero\n",
    "    \n",
    "    for k in range(len(lines_sv)):\n",
    "        words_sv = word_split(lines_sv[k])\n",
    "        words_en = word_split(lines_en[k])\n",
    "        for i in range(len(words_sv)): # words_sv[i] stands for each sv word\n",
    "            sum_trans = 0\n",
    "            for j in range(len(words_en)): # words_en[j] stands for each en word\n",
    "                sum_trans += df_trans.at[words_en[j],words_sv[i]]\n",
    "                #print(sum_trans)\n",
    "            for j in range(len(words_en)):\n",
    "                align_prob = df_trans.at[words_en[j],words_sv[i]]/sum_trans\n",
    "                df_counts.at[words_en[j],words_sv[i]] += align_prob\n",
    "                df_counts_en.at[words_en[j],'c(e)'] += align_prob\n",
    "    df_trans = df_counts.div(df_counts_en['c(e)'],axis=0)\n",
    "    return df_trans\n",
    "\n",
    "def final_translate(df_trans,sentence,text):\n",
    "    word_list = sentence.split()\n",
    "    translate = []\n",
    "    for word in word_list:\n",
    "        df_trans = df_trans.sort_values(by=word,ascending=False)\n",
    "        translate.append(df_trans[[word]].head(3).index.values.tolist())\n",
    "        \n",
    "    from itertools import product\n",
    "    loop_val = translate\n",
    "    combine = []\n",
    "    for i in product(*loop_val):\n",
    "        combine.append(i)\n",
    "            \n",
    "    score = []\n",
    "    for option_list in combine:\n",
    "        p = lang_model(text,option_list)\n",
    "        score.append((option_list,p))\n",
    "    return score[-1][0]\n",
    "\n",
    "def final_translate_simplify(df_trans,sentence):\n",
    "    word_list = sentence.split()\n",
    "    translate = []\n",
    "    for word in word_list:\n",
    "        df_trans = df_trans.sort_values(by=word,ascending=False)\n",
    "        translate.append(df_trans[[word]].head(1).index.values.tolist())\n",
    "    return translate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QFZgdXF-DrIF",
    "outputId": "23182bb8-d634-4bc9-bd52-98804103b625"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the' 'of' 'to' 'and' 'in' 'is' 'that' 'a' 'we' 'this']\n",
      "['att' 'och' 'i' 'det' 'som' 'för' 'av' 'är' 'en' 'vi']\n",
      "3.890656976337024e-05\n"
     ]
    }
   ],
   "source": [
    "# Warmup\n",
    "text_en = open('/content/sample_data/europarl-v7.sv-en.lc.en').read()\n",
    "df_en = word_counts(text_en)\n",
    "print(df_en.head(10).index.values)\n",
    "\n",
    "text_sv = open('/content/sample_data/europarl-v7.sv-en.lc.sv').read()\n",
    "df_sv = word_counts(text_sv)\n",
    "print(df_sv.head(10).index.values)\n",
    "\n",
    "# probability of the word 'speaker'\n",
    "speaker = df_en.loc['speaker','Counts']/len(word_split(text_en))\n",
    "print(speaker)\n",
    "\n",
    "# probability of the word 'zebra'\n",
    "# zebra = df_en.loc['zebra','Counts']/len(word_split(text_en))\n",
    "# print(zebra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KGLMPoZ-lIsw",
    "outputId": "eb579cc2-1236-41a7-fe01-91f4db05fa9a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " please input a sentence:i am going to work\n",
      "4.1590933067782277e-08\n"
     ]
    }
   ],
   "source": [
    "# Language modeling\n",
    "sentence = input(\" please input a sentence:\")\n",
    "word_list = sentence.split()\n",
    "p = lang_model(text_en,word_list)\n",
    "print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xYoIZ7g8tgxb",
    "outputId": "f1742c38-d2af-4729-9823-f863a8c79298"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['att' 'och' 'europeiska' 'i' 'för' 'en' 'av' 'det' 'den' 'som']\n",
      "['europeiska' 'att' 'i' 'och' 'för' 'en' 'den' 'av' 'det' 'som']\n",
      "['europeiska' 'i' 'att' 'den' 'en' 'och' 'europeisk' 'för' 'av' 'unionen']\n",
      "['europeiska' 'europeisk' 'den' 'i' 'en' 'för' 'att' 'och' 'av' 'unionen']\n",
      "['europeiska' 'europeisk' 'den' 'i' 'en' 'för' 'att' 'och' 'av' 'unionen']\n"
     ]
    }
   ],
   "source": [
    "# Translation modeling\n",
    "lines_en = open('/content/sample_data/europarl-v7.sv-en.lc.en').readlines()\n",
    "lines_en_partial = lines_en[0:3000]\n",
    "text_en_partial = ''.join(lines_en_partial)\n",
    "\n",
    "lines_sv = open('/content/sample_data/europarl-v7.sv-en.lc.sv').readlines()\n",
    "lines_sv_partial = lines_sv[0:3000]\n",
    "text_sv_partial = ''.join(lines_sv_partial)\n",
    "\n",
    "# initiate word alignment probability table\n",
    "df_en = word_counts(text_en_partial)\n",
    "df_sv = word_counts(text_sv_partial)\n",
    "df_trans = pd.DataFrame(index=df_en.index,columns=df_sv.index)\n",
    "df_trans.iloc[:]=0.25\n",
    "\n",
    "t = 5\n",
    "for i in range(t):\n",
    "    df_trans = trans_model(text_en_partial,text_sv_partial,lines_en_partial,lines_sv_partial,df_trans)\n",
    "    df_trans_sort = df_trans.sort_values(axis=1,by='european',ascending=False)\n",
    "    print(df_trans_sort.loc['european'].index.values[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yg6IeDnFgEpz",
    "outputId": "9f9fe9d6-0e2e-4b0d-a8b1-610c1deef0c2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input as: jag går till skolan \n",
      "Translated into: [['i'], ['yesterday'], ['access'], ['school']]\n",
      "Input as: gott nytt år \n",
      "Translated into: [['sound'], ['millennium'], ['year']]\n",
      "Input as: frågan är hård \n",
      "Translated into: [['question'], ['is'], ['tough']]\n"
     ]
    }
   ],
   "source": [
    "# Decoding-Simplified method\n",
    "sentence = 'jag går till skolan'\n",
    "print('Input as:',sentence,'\\nTranslated into:',final_translate_simplify(df_trans,sentence))\n",
    "\n",
    "sentence = 'gott nytt år'\n",
    "print('Input as:',sentence,'\\nTranslated into:',final_translate_simplify(df_trans,sentence))\n",
    "\n",
    "sentence = 'frågan är hård'\n",
    "print('Input as:',sentence,'\\nTranslated into:',final_translate_simplify(df_trans,sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "agOkOrVGzlj-"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "NLP_v1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
